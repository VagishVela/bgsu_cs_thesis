{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_OSC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup script to run on OSC\n",
    "# conda install scikit-learn matplotlib nltk seaborn\n",
    "# pip install git+https://github.com/titipata/pubmed_parser.git@0.3.1\n",
    "# conda install -c conda-forge hummingbird-ml\n",
    "# conda install ipykernel\n",
    "# ipython kernel install --user --name=thesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import pubmed_parser as pp\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one pub-med dictionary entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_OSC:\n",
    "    data_path = \"/ftp.ncbi.nlm.nih.gov/pubmed/baseline/\"\n",
    "else:\n",
    "    data_path = '../../data/raw'\n",
    "path_xml = pp.list_xml_path(data_path) # list all xml paths under directory\n",
    "pubmed_dict = pp.parse_medline_xml(path_xml[0]) # dictionary output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it into a dataframe and output the head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pubmed_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the missing abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['abstract'] != '']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique mesh terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_terms_arr = []\n",
    "[mesh_terms_arr.extend(mesh_terms.split('; ')) for mesh_terms in df.mesh_terms.to_list()]\n",
    "unique_mesh_terms = set(mesh_terms_arr)\n",
    "\n",
    "# Display the first 20 unique terms\n",
    "list(unique_mesh_terms)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the mesh terms to the dataframe as columns. This does take about 5 minutes to run per volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mesh_term in tqdm(unique_mesh_terms):\n",
    "    df[mesh_term] = df.mesh_terms.apply(lambda x: 1 if mesh_term in x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the head of the dataframe to see if the mesh terms were added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the counts of the mesh terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_term_counts = []\n",
    "for mesh_term in tqdm(unique_mesh_terms):\n",
    "    mesh_term_counts.append((mesh_term, df[mesh_term].sum()))\n",
    "mesh_term_counts = sorted(mesh_term_counts, key=lambda x: x[1], reverse=True)\n",
    "mesh_term_df = pd.DataFrame(mesh_term_counts, columns=['mesh_term', 'count'])\n",
    "mesh_term_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the top 20 mesh terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_term_df.head(20).plot.bar(x='mesh_term', y='count', figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many mesh terms are there per article?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_of_mesh_terms_per_article = df.iloc[:,22:].sum(axis=1).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_mesh_terms_per_article.plot.bar(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, random_state=42, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.abstract + ' ' + train.title\n",
    "X_test = test.abstract + ' ' + test.title\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline with a multi label classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_effectiveness(name, pipeline):\n",
    "    with open(name + '-accuracy.csv','w') as f1:\n",
    "        writer=csv.writer(f1, delimiter=',',lineterminator='\\n')\n",
    "        writer.writerow(['mesh_term','term_count','prediction_count','accuracy','precision','recall'])\n",
    "        for mesh_term in tqdm(unique_mesh_terms):\n",
    "            # train the model using X_dtm & y\n",
    "            pipeline.fit(X_train, train[mesh_term])\n",
    "            # compute the testing accuracy\n",
    "            prediction = pipeline.predict(X_test)\n",
    "            if prediction.sum() > 0:\n",
    "                print('mesh_term: ', mesh_term)\n",
    "                print(test[mesh_term].sum())\n",
    "                print(prediction.sum())\n",
    "                print('Test accuracy is {}'.format(accuracy_score(test[mesh_term], prediction)))\n",
    "                print('Test precision is {}'.format(precision_score(test[mesh_term], prediction)))\n",
    "                print('Test recall is {}'.format(recall_score(test[mesh_term], prediction)))\n",
    "\n",
    "\n",
    "            writer.writerow([\n",
    "                mesh_term, \n",
    "                test[mesh_term].sum(),\n",
    "                prediction.sum(),\n",
    "                accuracy_score(test[mesh_term], prediction), \n",
    "                precision_score(test[mesh_term], prediction), \n",
    "                recall_score(test[mesh_term], prediction)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "classifier_effectiveness('nb', NB_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "classifier_effectiveness('svc', SVC_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "classifier_effectiveness('logreg', LogReg_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d56fa87c78b39559b1c08cc8dd1bbbef7b63a80b01222ac7427efbc04ea0dd45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
